import streamlit as st
import gdown
import zipfile
import os
import shutil
import json
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification

#https://drive.google.com/file/d/10pcCB-47bl-jQ53t8AB1_F0LD6wHNwIU/view?usp=sharing

#https://drive.google.com/file/d/1bfdQHkuHS-Y9ww9AjEslazRqEc_hL47f/view?usp=sharing

# URLs Google Drive (fichier ZIP + mÃ©triques)
ZIP_NAME = "transformer_model.zip"
EXTRACT_DIR = "transformer_model_extracted"
METRICS_FILE = "metrics_transformers.json"
DRIVE_ZIP_URL = "https://drive.google.com/uc?id=10pcCB-47bl-jQ53t8AB1_F0LD6wHNwIU"
DRIVE_METRICS_URL = "https://drive.google.com/uc?id=1bfdQHkuHS-Y9ww9AjEslazRqEc_hL47f"

# ğŸ“¥ TÃ©lÃ©charger et charger le modÃ¨le
@st.cache_resource
def load_model():
    if os.path.exists(EXTRACT_DIR):
        shutil.rmtree(EXTRACT_DIR)
    os.makedirs(EXTRACT_DIR, exist_ok=True)

    # TÃ©lÃ©charger le ZIP
    gdown.download(DRIVE_ZIP_URL, ZIP_NAME, quiet=False)

    # Extraire le modÃ¨le
    with zipfile.ZipFile(ZIP_NAME, "r") as zip_ref:
        zip_ref.extractall(EXTRACT_DIR)

    # Charger tokenizer + modÃ¨le
    tokenizer = AutoTokenizer.from_pretrained(EXTRACT_DIR)
    model = AutoModelForTokenClassification.from_pretrained(EXTRACT_DIR)
    ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")
    return ner_pipeline

# ğŸ“¥ TÃ©lÃ©charger et charger les mÃ©triques
@st.cache_data
def load_metrics():
    if not os.path.exists(METRICS_FILE):
        gdown.download(DRIVE_METRICS_URL, METRICS_FILE, quiet=False)
    with open(METRICS_FILE, "r") as f:
        return json.load(f)

# Initialisation
ner = load_model()
metrics = load_metrics()

# Navigation
st.sidebar.title("ğŸ§­ Navigation")
page = st.sidebar.radio("Aller Ã  :", ["ğŸ  Accueil", "ğŸ“Š Performances", "ğŸ“ DÃ©tection d'entitÃ©s"])

# Pages
if page == "ğŸ  Accueil":
    st.title("ğŸ” DÃ©tection d'entitÃ©s nommÃ©es (NER)")
    st.markdown("""
    Ce modÃ¨le de Reconnaissance d'EntitÃ©s NommÃ©es (NER) utilise l'architecture Transformers pour identifier les entitÃ©s dans vos textes.

    **Technologie utilisÃ©e :** Hugging Face Transformers  
    **Source :** ModÃ¨le entraÃ®nÃ© sur des donnÃ©es personnalisÃ©es
    """)

elif page == "ğŸ“Š Performances":
    st.title("ğŸ“ˆ Performances du modÃ¨le")

    precision = metrics['ents_p']
    recall = metrics['ents_r']
    f1 = metrics['ents_f']
    accuracy = (precision + recall) / 2

    st.metric("ğŸ¯ PrÃ©cision", f"{precision:.2f}%")
    st.metric("ğŸ“¥ Rappel", f"{recall:.2f}%")
    st.metric("âš–ï¸ F1-Score", f"{f1:.2f}%")
    st.metric("â­ Accuracy", f"{accuracy:.2f}%")

elif page == "ğŸ“ DÃ©tection d'entitÃ©s":
    st.title("ğŸ“ Entrez un texte Ã  analyser")
    text = st.text_area("Tapez ici votre texte...")
    if st.button("Analyser"):
        if text.strip():
            results = ner(text)
            st.markdown("### ğŸ“Œ EntitÃ©s dÃ©tectÃ©es :")
            for ent in results:
                st.write(f"**{ent['word']}** â†’ *{ent['entity_group']}* ({ent['score']:.2f})")
        else:
            st.warning("Veuillez entrer un texte.")
